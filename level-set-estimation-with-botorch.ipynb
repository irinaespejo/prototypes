{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Estimation of level sets with BoTorch\n",
    "\n",
    "following the entry level tutorial here https://botorch.org but I have also browsed extensively along Bite-sized and full-loop tutorials"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Low dimension / low data (no fancy sampling)\n",
    "\n",
    "Problem in 1-d: $f_{BlackBox}(x) = 2*sin(x) - x$ at threshold $t=3.$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from botorch.utils import standardize\n",
    "\n",
    "#true toy function\n",
    "def f(x: Tensor):\n",
    "    return torch.sin(7*x)\n",
    "\n",
    "#threshold\n",
    "t = 0.25\n",
    "\n",
    "#generate truth data\n",
    "true_x = torch.arange(0, 1, 0.01).double()\n",
    "true_y = f(true_x).double()\n",
    "\n",
    "#generate std training data\n",
    "train_x = torch.rand(2,1).double()\n",
    "train_y = f(train_x).double()\n",
    "train_y_std = standardize(train_y).double()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# helper function\n",
    "from typing import Optional\n",
    "def make_plot(mean: Optional=None, std: Optional=None, new_x: Optional=None):\n",
    "    if mean is not None:\n",
    "        plt.plot(true_x.detach().numpy(), mean, color='blue', label='mean');\n",
    "    if std is not None:\n",
    "        plt.fill_between(true_x.detach().numpy(), mean-std, mean+std, color='lightblue', label='std');\n",
    "    if new_x is not None:\n",
    "        plt.scatter(new_x.detach().numpy(), f(new_x).detach().numpy(), color='red', marker='o')\n",
    "        plt.vlines(new_x.detach().numpy(),np.max(true_y.detach().numpy()),np.min(true_y.detach().numpy()), color='grey', linewidth=1)\n",
    "\n",
    "    plt.plot(true_x, true_y, color='black', linestyle='--', label='true');\n",
    "    plt.scatter(train_x.detach().numpy(), train_y.detach().numpy(), color='red', marker='o', label='train')\n",
    "    plt.hlines(t, 0, 1, color='grey', label=f'threshold={t}');\n",
    "    plt.ylim([-1,1])\n",
    "    mask = (torch.abs(true_y-t) < 0.5*10E-2).nonzero()\n",
    "    plt.scatter(true_x[mask].detach().numpy(), f(true_x[mask]).detach().numpy() , color='black', marker='o', label='goal', facecolors='none')\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "    \n",
    "make_plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#train model \n",
    "from botorch.models import FixedNoiseGP\n",
    "from botorch import fit_gpytorch_model\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "#helper function\n",
    "def init_model(train_x: Tensor , train_y: Tensor, state_dict=None):\n",
    "    noise = torch.full_like(train_y, 0.)\n",
    "    gp = FixedNoiseGP(train_x, train_y, noise);\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp);\n",
    "    if state_dict is not None:\n",
    "        gp.load_state_dict(state_dict)\n",
    "    return gp, mll\n",
    "    \n",
    "gp, mll = init_model(train_x, train_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from botorch.acquisition.objective import ScalarizedObjective\n",
    "from botorch.models.model import Model\n",
    "import math\n",
    "\n",
    "#helper function\n",
    "def cdf(mu, sigma, t):\n",
    "    mu_reshape = torch.stack([mu,mu], dim=1)\n",
    "    sigma_reshape = torch.stack([sigma, sigma], dim=1)\n",
    "    erf = torch.erf((t - mu_reshape) * (sigma_reshape).reciprocal() / math.sqrt(2))\n",
    "    cdf = 0.5 * (1 + erf)\n",
    "    return cdf \n",
    "\n",
    "\n",
    "class MaximumEntropySearch(AnalyticAcquisitionFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: Model,\n",
    "        threshold: Tensor,\n",
    "        objective: Optional[ScalarizedObjective] = None,\n",
    "        maximize: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__(model=model, objective=objective)\n",
    "        # self.maximize = maximize\n",
    "        self.thr = threshold\n",
    "        infty = 1E10\n",
    "        self.thresholds = [-infty] + self.thr.tolist() + [infty]\n",
    "        self.pairs_thresholds = list(zip(self.thresholds, self.thresholds[1:]))\n",
    "        self.pairs_thresholds = [torch.Tensor(pair) for pair in self.pairs_thresholds]\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        posterior = self._get_posterior(X=X)\n",
    "        batch_shape = X.shape[:-2]\n",
    "        mean = posterior.mean.view(batch_shape).double()\n",
    "        std = torch.square(posterior.variance.view(batch_shape).double())\n",
    "        #probability of image being between thresholds\n",
    "        p = cdf(mean, std, self.pairs_thresholds[1]) - cdf(mean, std, self.pairs_thresholds[0])\n",
    "        probs = torch.cat([p, 1-p])\n",
    "        #create bernoulli distribution\n",
    "        distr = torch.distributions.Categorical(probs)\n",
    "        #entropy\n",
    "        entropy = distr.entropy().view(-1)\n",
    "        return entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "import numpy as np\n",
    "\n",
    "bounds = torch.stack([torch.zeros(1), torch.ones(1)]).double()\n",
    "threshold = torch.Tensor([t]) \n",
    "threshold.requires_grad=True\n",
    "N_TRIALS = 15\n",
    "N_Q = 1\n",
    "N_RESTART = 1\n",
    "N_SAMPLES = 1 \n",
    "\n",
    "for i in range(1, N_TRIALS+1):\n",
    "    \n",
    "    fit_gpytorch_model(mll)\n",
    "    \n",
    "    #find suggestions\n",
    "    MES = MaximumEntropySearch(gp, threshold=threshold)\n",
    "    \n",
    "    candidate, _ = optimize_acqf(\n",
    "        MES, bounds=bounds, q=N_Q, num_restarts=N_RESTART, raw_samples=N_SAMPLES,\n",
    "    )\n",
    "    print(f\"Suggestion iteration {i}: x_new = {candidate.item()}\")\n",
    "    \n",
    "    #update training set\n",
    "    train_x = torch.vstack([train_x, candidate[0]])\n",
    "    train_y = torch.vstack([train_y, f(candidate[0])])\n",
    "    \n",
    "    #update fit\n",
    "    gp, mll = init_model(train_x, train_y, gp.state_dict())    \n",
    "    \n",
    "    #plot fit\n",
    "    mean = gp.posterior(true_x).mean.detach().numpy().flatten()\n",
    "    std = np.sqrt(gp.posterior(true_x).variance.detach().numpy().flatten())\n",
    "    make_plot(mean=mean, std=std, new_x = candidate)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('lse': venv)"
  },
  "interpreter": {
   "hash": "0c66e9db9667e10910889fd0586884c0dd299489e73d9ae3bcf94d0bdba224f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}